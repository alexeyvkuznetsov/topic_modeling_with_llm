{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "##Анализ тематики дневника К.А.Березкина\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9uUWZMQ3oUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LJJ-ZoZh2BMj",
        "outputId": "068936ce-cbba-4bf4-8c18-fc5e08020650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключение Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lt7_PNE2Q8z",
        "outputId": "c8ecdb9e-8be2-4d77-e5e8-edbd0d0bdb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Настройка API\n",
        "\n",
        "PROXY_API_KEY = \"PROXY_API_KEY\" # Вставьте ваш PROXY_API_KEY\n",
        "\n",
        "# Настройка путей\n",
        "base_dir = \"/content/drive/My Drive/DIARY\"\n",
        "input_folder = os.path.join(base_dir, 'texts')\n",
        "data_folder = os.path.join(base_dir, 'data')\n",
        "\n",
        "# Функция для чтения всех текстовых файлов и создания DataFrame\n",
        "def create_dataframe_from_files(input_folder):\n",
        "    files = sorted([f for f in os.listdir(input_folder) if f.endswith('.txt')])\n",
        "    data = []\n",
        "    for file in files:\n",
        "        file_path = os.path.join(input_folder, file)\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "        data.append({'filename': file, 'text': text})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Чтение текстов из файлов в папку \"texts\" и создание DataFrame\n",
        "df = create_dataframe_from_files(input_folder)\n",
        "\n",
        "# Сохранение DataFrame в CSV файл\n",
        "df.to_csv(os.path.join(data_folder, 'diary_dataframe.csv'), index=False, encoding='utf-8')\n",
        "print(\"DataFrame сохранен в файл 'diary_dataframe.csv'.\")\n",
        "\n",
        "# Системный промпт\n",
        "system_prompt = \"\"\"\n",
        "Вы — эксперт по истории Российской Империи XIX века и специалист по анализу личных дневников и мемуаров со знанием культурных, исторических и социальных аспектов этого периода. Ваша роль заключается в анализе текста дневника и идентификации ключевых тем с подробными объяснениями.\n",
        "\n",
        "Контекст:\n",
        "- Автор дневника: Кирилл Антонович Березкин, гимназист Вологодской губернской гимназии, потомственный дворянин.\n",
        "- Период ведения дневника: январь 1849 - сентябрь 1849.\n",
        "- Место: город Вологда, Вологодская губерния.\n",
        "- Историческая значимость: дневник отражает восприятие важных исторических событий в российской провинции.\n",
        "\n",
        "План действий:\n",
        "1. Прочитайте предоставленный текст дневника и оцените его содержание.\n",
        "2. Определите ключевые темы, о которых пишет автор, основываясь на частоте упоминаний, значимости для автора и эмоциональной окраске.\n",
        "3. Для каждой темы составьте краткое название и подробное описание, учитывающее исторический и культурный контекст середины XIX века в Вологде.\n",
        "4. Найдите и приведите примеры в виде цитат (с указанием даты записи), которые подтверждают наличие этой темы.\n",
        "5. Убедитесь, что описание каждой темы детально отражает её значимость и связь с социальной, образовательной или культурной жизнью того времени.\n",
        "\n",
        "Методические рекомендации:\n",
        "- Подходите к анализу с междисциплинарной точки зрения, связывая темы с историей, социологией и педагогикой.\n",
        "- Выбирайте цитаты, которые наиболее репрезентативно и ярко иллюстрируют тему.\n",
        "\"\"\"\n",
        "\n",
        "# Настройка headers для API\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {PROXY_API_KEY}\"\n",
        "}\n",
        "\n",
        "# Функция для запроса к Gemini\n",
        "def get_themes_for_chunk(chunk):\n",
        "    user_prompt = f\"\"\"На основе системных инструкций проведите анализ тематики текста дневника гимназиста из Вологды середины XIX века. Определите и опишите все основные темы, обсуждаемые в дневнике. Представьте результаты в формате списка по следующей схеме:\n",
        "\n",
        "- **Название темы**: [краткое название темы]\n",
        "- **Описание**: [подробное описание темы (100 слов), включая её значимость и возможное отражение культурных и социальных реалий того времени]\n",
        "- **Пример**: [2-3 цитаты из текста дневника со ссылкой на дату записи, которые иллюстрируют эту тему и подчеркивают её значимость]\n",
        "\n",
        "Повторите эту схему для каждой найденной темы.\n",
        "\n",
        "{chunk}\"\"\"\n",
        "\n",
        "    # Создаем запрос к Gemini\n",
        "    payload = {\n",
        "        \"contents\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": system_prompt + \"\\n\\n\" + user_prompt}\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        \"generationConfig\": {\n",
        "            \"temperature\": 0.3,\n",
        "            \"maxOutputTokens\": 8024\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Отправка запроса\n",
        "    response = requests.post(\n",
        "        \"https://api.proxyapi.ru/google/v1/models/gemini-1.5-pro:generateContent\",\n",
        "        headers=headers,\n",
        "        data=json.dumps(payload)\n",
        "    )\n",
        "\n",
        "    # Обработка ответа\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result['candidates'][0]['content']['parts'][0]['text']\n",
        "    else:\n",
        "        print(f\"Ошибка: {response.status_code}, {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "# Файл для сохранения промежуточных результатов\n",
        "intermediate_results_path = os.path.join(data_folder, 'intermediate_themes_gemini.txt')\n",
        "\n",
        "with open(intermediate_results_path, 'w', encoding='utf-8') as f_out:\n",
        "    themes = []\n",
        "    for i, row in df.iterrows():\n",
        "        print(f\"Обработка файла {row['filename']} ({i+1}/{len(df)}):\")\n",
        "        chunk = row['text']\n",
        "        themes_chunk = get_themes_for_chunk(chunk)\n",
        "\n",
        "        # Сохраняем промежуточный результат\n",
        "        f_out.write(f\"Файл: {row['filename']}\\n\")\n",
        "        f_out.write(themes_chunk)\n",
        "        f_out.write(\"\\n---\\n\")  # Разделитель\n",
        "\n",
        "        themes.append(themes_chunk)\n",
        "\n",
        "# Обобщение всех тем\n",
        "all_themes = \"\\n\".join(themes)\n",
        "prompt_summary = f\"Вот список ключевых тем нескольких частей одного текста. Обобщите информацию и составте общий список основных тем всего текста с комментариями: \\n\\n{all_themes}\"\n",
        "\n",
        "# Запрос на обобщение\n",
        "payload_summary = {\n",
        "    \"contents\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"parts\": [\n",
        "                {\"text\": \"Вы являетесь экспертом по анализу и обобщению информации.\" + \"\\n\\n\" + prompt_summary}\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"generationConfig\": {\n",
        "        \"temperature\": 0.5,\n",
        "        \"maxOutputTokens\": 8024\n",
        "    }\n",
        "}\n",
        "\n",
        "response_summary = requests.post(\n",
        "    \"https://api.proxyapi.ru/google/v1/models/gemini-1.5-pro:generateContent\",\n",
        "    headers=headers,  # Здесь headers определен ранее\n",
        "    data=json.dumps(payload_summary)\n",
        ")\n",
        "\n",
        "# Обработка итогового обобщения\n",
        "if response_summary.status_code == 200:\n",
        "    summary = response_summary.json()['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "    # Сохранение итогового обобщения\n",
        "    with open(os.path.join(data_folder, 'summary_themes_gemini.txt'), 'w', encoding='utf-8') as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(\"Анализ завершен. Промежуточные результаты сохранены в 'intermediate_themes_gemini.txt', итоговое обобщение сохранено в 'summary_themes_gemini.txt'.\")\n",
        "else:\n",
        "    print(f\"Ошибка при обобщении: {response_summary.status_code}, {response_summary.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKmF5dgyRI8w",
        "outputId": "881f4305-438d-41ee-d61b-d871e9a2a639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame сохранен в файл 'diary_dataframe.csv'.\n",
            "Обработка файла 01.txt (1/9):\n",
            "Обработка файла 02.txt (2/9):\n",
            "Обработка файла 03.txt (3/9):\n",
            "Обработка файла 04.txt (4/9):\n",
            "Обработка файла 05.txt (5/9):\n",
            "Обработка файла 06.txt (6/9):\n",
            "Обработка файла 07.txt (7/9):\n",
            "Обработка файла 08.txt (8/9):\n",
            "Обработка файла 09.txt (9/9):\n",
            "Анализ завершен. Промежуточные результаты сохранены в 'intermediate_themes_gemini.txt', итоговое обобщение сохранено в 'summary_themes_gemini.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "erNrP4frDFEt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}